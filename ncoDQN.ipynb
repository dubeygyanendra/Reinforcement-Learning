{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ncoDQN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv8X4C1Cf1xM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "a485f5ef-df9b-4ed8-edd4-a83a2b5e1f6f"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=7cddb66b4ee6df67ae78bc19fcd8e6782762eb6137c184fd16d7aa60cebb8c8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu0M5g3kf4Lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTBB2fhmf7Ia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "532d833c-83d4-4fe2-98b2-006e081e3b85"
      },
      "source": [
        "def printmg():\n",
        "  GPUs = GPU.getGPUs()\n",
        "  gpu = GPUs[0]\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printmg()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.8 GB  | Proc size: 158.3 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e30z_a_2gCs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-RWNoO_98hK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "from IPython.display import clear_output\n",
        "from tqdm.notebook import tqdm\n",
        "from tensorflow.keras.layers import Activation, Dense, LeakyReLU, PReLU, ReLU, BatchNormalization,Embedding,Attention,LSTM,TimeDistributed, Bidirectional,Input \n",
        "from tensorflow.keras.layers import Lambda, Flatten, add, Conv1D, RNN, multiply\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPkQaiux9_O9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "  \n",
        "  def __init__(self, shapes):\n",
        "    \n",
        "    #vocab_size, embedding_dim, enc_units, batch_sz = shapes\n",
        "    self.batch_sz = shapes[3]\n",
        "    self.enc_units = shapes[2]\n",
        "    self.vocab_size = shapes[0]\n",
        "    self.embedding_dim = shapes[1]\n",
        "  \n",
        "\n",
        "  def estimator(self):\n",
        "    inp = Input(shape = (1), name = 'input')\n",
        "    dspace = Input(shape = (5), name = 'space')\n",
        "    init = Input(shape = (1), name = 'init')\n",
        "    space = Dense(128, activation = 'tanh')(dspace)\n",
        "    f_h_state = Dense(128, activation = 'tanh')(init)\n",
        "    f_c_state = Dense(128, activation = 'tanh')(init)\n",
        "    b_h_state = Dense(128, activation = 'tanh')(init)\n",
        "    b_c_state = Dense(128, activation = 'tanh')(init)\n",
        "    f_state = Dense(128, activation = 'tanh')(init)\n",
        "    b_state = Dense(128, activation = 'tanh')(init)\n",
        "    model = Embedding(self.vocab_size, self.embedding_dim)(inp)\n",
        "    model = Bidirectional(LSTM(self.enc_units,return_sequences = True, recurrent_initializer='glorot_uniform'))(model, initial_state=[f_h_state, f_c_state, b_h_state, b_c_state])\n",
        "    model = Bidirectional(LSTM(self.enc_units, recurrent_initializer='glorot_uniform'))(model, initial_state=[f_state, space, b_state, space])\n",
        "    model = Dense(128, activation = 'relu')(model)\n",
        "    model = Dense(5, activation = 'relu')(model)\n",
        "    val = Model(inputs = [inp, dspace, init], outputs = model)\n",
        "    return val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl5LYugvBO22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agent1 = Agent((200, 10, 128, 1)).estimator()\n",
        "agent2 = Agent((200, 10, 128, 1)).estimator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luY43esgBPxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agent2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OELoOGg4mFMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cell = np.ones((128,1))\n",
        "#value = agent.predict({'input':data,'space':space,'init':cell})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHIhaDL-HZZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_all_rewards(state, data):\n",
        "  action = tf.one_hot([0,1,2,3,4],5,dtype = tf.float32)\n",
        "  rewards = []\n",
        "  for i in range(len(action)):\n",
        "    prev_space = tf.math.divide_no_nan(tf.cast(tf.math.count_nonzero(state, axis = 1), dtype = tf.float32), 1.0)\n",
        "    new_state = state + tf.math.multiply(tf.broadcast_to(action[i], [128,5] ), (tf.reshape(data[:,0],[128,1])))\n",
        "    new_space = tf.math.divide_no_nan(tf.cast(tf.math.count_nonzero(new_state, axis = 1), dtype = tf.float32), 1.0)\n",
        "    reward = new_space - prev_space\n",
        "    rewards.append(tf.reshape(reward,[128,1]))\n",
        "  rewards = tf.concat(rewards, axis = 1)\n",
        "  return rewards"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6MbblYhXxNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_all_Q(state, data, choice):\n",
        "  rewards = compute_all_rewards(state, data)\n",
        "  action = tf.expand_dims(tf.one_hot([0,1,2,3,4],5,dtype = tf.float32), 1)\n",
        "  states = tf.math.multiply(action, tf.cast(tf.reshape(data[:,0],[128,1]),dtype = tf.float32)) + state\n",
        "  qs = []\n",
        "  for i in range(5):\n",
        "    if choice == 1:\n",
        "      p = agent1.predict({'input':data[:,1:],'space':states[i],'init':cell})\n",
        "      index = tf.math.argmax(p, axis = -1)\n",
        "      q = agent2.predict({'input':data[:,1:],'space':states[i],'init':cell})\n",
        "      q = tf.math.multiply(q, tf.one_hot(index,5))\n",
        "    else:\n",
        "      p = agent2.predict({'input':data[:,1:],'space':states[i],'init':cell})\n",
        "      index = tf.math.argmax(p, axis = -1)\n",
        "      q = agent1.predict({'input':data[:,1:],'space':states[i],'init':cell})\n",
        "      q = tf.math.multiply(q, tf.one_hot(index,5))\n",
        "    q = tf.math.reduce_max(q, axis = 1)\n",
        "    qs.append(tf.expand_dims(q,axis = -1))\n",
        "  qs = tf.concat(qs, axis = -1)\n",
        "  estimate = qs + rewards\n",
        "  return estimate\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTQpiwW9XNhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(input_data):\n",
        "    return input_data.astype(np.float32)/1000.0\n",
        "sz = [random.randrange(2,13,1) for i in range(500)]    \n",
        "tr = []\n",
        "for i in sz:\n",
        "  sq = [random.sample(range(1,200),i) for j in range(128)]\n",
        "  tr.append(tf.convert_to_tensor(normalize(np.array(sq))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35fPHkXvTOeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def s_loss(action, truth):\n",
        "  return K.abs(action-truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDTvKEBgXuBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "agent1.compile(loss = s_loss, optimizer = adam)\n",
        "agent2.compile(loss = s_loss, optimizer = adam)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZIok_DMFFjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agent1.load_weights('./agent1_18.h5')\n",
        "agent2.load_weights('./agent1_18.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haKI95n7VYGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqspC4loaqKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_num = len(tr)\n",
        "epoch = 1000\n",
        "batch_size = 128\n",
        "capacity = np.array([[500,400,300,200,100] for i in range(128)])\n",
        "capacity = normalize(capacity)\n",
        "capacity = tf.convert_to_tensor(capacity,dtype = tf.float32)\n",
        "cell = tf.convert_to_tensor(np.ones((128,1)),dtype = tf.float32)\n",
        "l = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvbQ9PKt5AO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "for e in range(4,epoch+1):\n",
        "  losses = 0\n",
        "  for num in tqdm(range(batch_num)):\n",
        "    state = tf.convert_to_tensor(np.zeros((batch_size,5)),dtype = tf.float32)\n",
        "    choice = np.random.choice([0,1])\n",
        "    data = tr[num]\n",
        "    loss = 0\n",
        "    for i in range(len(data[1])):\n",
        "      dynamic_state = capacity-state\n",
        "      if i<len(data[1])-1:\n",
        "        q_values = compute_all_Q(dynamic_state, data[:,i:], choice)\n",
        "        total = q_values\n",
        "      else:\n",
        "        total = compute_all_rewards(dynamic_state, data[:,i:])\n",
        "      #masking the reward to assign 0 probability to filled states\n",
        "      expected_dynamic_state = tf.math.add(dynamic_state, -tf.reshape(data[:,i],[128,1]))\n",
        "      cond = tf.math.less_equal(expected_dynamic_state,[0])\n",
        "      inf = tf.convert_to_tensor(np.ones(state.shape)*-np.inf, dtype = tf.float32)\n",
        "      total = total.numpy()\n",
        "      if choice == 1:\n",
        "        loss += agent2.train_on_batch({'input':data[:,i:],'space':dynamic_state,'init':cell}, total)\n",
        "        action = agent2.predict({'input':data[:,i:],'space':dynamic_state,'init':cell})\n",
        "      else:\n",
        "        loss += agent1.train_on_batch({'input':data[:,i:],'space':dynamic_state,'init':cell}, total)\n",
        "        action = agent1.predict({'input':data[:,i:],'space':dynamic_state,'init':cell})\n",
        "      action_probs = tf.math.divide_no_nan(1.0,action)\n",
        "      action_probs = tf.where(cond, inf, action_probs)\n",
        "      action_probs = tf.nn.softmax(action_probs)\n",
        "      action = tf.random.categorical(action,1)\n",
        "      action = tf.one_hot(tf.squeeze(action, axis = -1),5,dtype = tf.float32)\n",
        "      state = (tf.math.divide_no_nan(tf.math.multiply(action, tf.cast(tf.reshape(data[:,i],[128,1]),dtype = tf.float32)), 1.0 ) + state)\n",
        "    losses += loss/len(data[1])\n",
        "  l.append(losses/batch_num)\n",
        "  clear_output()\n",
        "  print(e, losses/batch_num)\n",
        "  plt.plot(l)\n",
        "  plt.show()\n",
        "  path1 = 'agent1'+str(e)+'.h5'\n",
        "  path2 = 'agent2'+str(e)+'.h5'\n",
        "  agent1.save(path1)\n",
        "  agent2.save(path2)\n",
        "  #shutil.copy(\"./\"+path1,\"/content/drive/My Drive/NCO/\"+path1)\n",
        "  #shutil.copy(\"./\"+path2,\"/content/drive/My Drive/NCO/\"+path2)\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHMwiMzBGr3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agent1.save_weights('./abc.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO_p3hRCFkVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "9710d780-4b72-4e33-e054-eade30a778be"
      },
      "source": [
        "g_items"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bidirectional', <Closed HDF5 group>),\n",
              " ('bidirectional_1', <Closed HDF5 group>),\n",
              " ('dense', <Closed HDF5 group>),\n",
              " ('dense_1', <Closed HDF5 group>),\n",
              " ('dense_2', <Closed HDF5 group>),\n",
              " ('dense_3', <Closed HDF5 group>),\n",
              " ('dense_4', <Closed HDF5 group>),\n",
              " ('dense_5', <Closed HDF5 group>),\n",
              " ('dense_6', <Closed HDF5 group>),\n",
              " ('dense_7', <Closed HDF5 group>),\n",
              " ('dense_8', <Closed HDF5 group>),\n",
              " ('embedding', <Closed HDF5 group>),\n",
              " ('init', <Closed HDF5 group>),\n",
              " ('input', <Closed HDF5 group>),\n",
              " ('space', <Closed HDF5 group>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XQCtRvsZ7qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total = tf.ones((128,5), dtype = tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaua27nSVAMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "with h5py.File('./agent125.h5','r') as hdf:\n",
        "  g_items = list(hdf.items())\n",
        "  g = hdf.get('model_weights')\n",
        "  g_items = list(g.items())\n",
        "  g1 = g.get('dense')\n",
        "  g_items = list(g1.items())\n",
        "  g11 = g1.get('dense')\n",
        "  '''g_items = list(g11.items())\n",
        "  g111 = g11.get('backward_lstm')\n",
        "  g_items = list(g111.items())\n",
        "  g1111 = g111.get('lstm_cell_2')\n",
        "  g_items = list(g1111.items())'''\n",
        "  g11111 = np.array(g11.get('kernel:0'))\n",
        "  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkrUgQy4F-lD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g11111"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGO_ge08hAf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8bbe39a-0d26-4c3d-81cc-abb498822bcb"
      },
      "source": [
        "agent1.train_on_batch({'input':data[:,i:],'space':dynamic_state,'init':cell}, total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9357037544250488"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAtnJr2ED5Ge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7389c3ea-4d02-4803-fd4e-8f408c0471b8"
      },
      "source": [
        "agent2.train_on_batch({'input':data[:,i:],'space':dynamic_state,'init':cell}, total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.978537917137146"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTE5DPD-g9Rv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state = tf.convert_to_tensor(np.zeros((batch_size,5)),dtype = tf.float32)\n",
        "for i in range(len(data[1])):\n",
        "  dynamic_state = capacity-state\n",
        "  expected_dynamic_state = tf.math.add(dynamic_state, -tf.reshape(data[:,i],[128,1]))\n",
        "  cond = tf.math.less_equal(expected_dynamic_state,[0])\n",
        "  inf = tf.convert_to_tensor(np.ones(state.shape)*-np.inf, dtype = tf.float32)\n",
        "  action = agent1.predict({'input':data[:,i:],'space':dynamic_state,'init':cell})\n",
        "  action_probs = tf.math.divide_no_nan(1.0,action)\n",
        "  action_probs = tf.where(cond, inf, action_probs)\n",
        "  action_probs = tf.nn.softmax(action_probs)\n",
        "  action = tf.math.argmax(action_probs,axis = 1)\n",
        "  action = tf.cast(tf.expand_dims(action, axis = -1), dtype = tf.int64)\n",
        "  action = tf.one_hot(tf.squeeze(action, axis = -1),5,dtype = tf.float32)\n",
        "  state = tf.math.multiply(action, tf.cast(tf.reshape(data[:,i],[128,1]),dtype = tf.float32))  + state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iczzS1oQNu4C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28f523de-1df1-4ce8-8f39-e5335aefdb03"
      },
      "source": [
        "state"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 5), dtype=float32, numpy=\n",
              "array([[0.499     , 0.359     , 0.288     , 0.        , 0.        ],\n",
              "       [0.484     , 0.377     , 0.189     , 0.143     , 0.        ],\n",
              "       [0.47400004, 0.359     , 0.17      , 0.        , 0.        ],\n",
              "       [0.48899996, 0.376     , 0.239     , 0.173     , 0.        ],\n",
              "       [0.49999997, 0.333     , 0.        , 0.        , 0.        ],\n",
              "       [0.492     , 0.36699998, 0.254     , 0.        , 0.        ],\n",
              "       [0.483     , 0.37199998, 0.198     , 0.        , 0.        ],\n",
              "       [0.49000004, 0.335     , 0.137     , 0.        , 0.        ],\n",
              "       [0.473     , 0.282     , 0.284     , 0.169     , 0.        ],\n",
              "       [0.495     , 0.37199998, 0.        , 0.        , 0.        ],\n",
              "       [0.47500002, 0.352     , 0.176     , 0.131     , 0.        ],\n",
              "       [0.471     , 0.368     , 0.282     , 0.129     , 0.        ],\n",
              "       [0.486     , 0.321     , 0.        , 0.        , 0.        ],\n",
              "       [0.5       , 0.376     , 0.        , 0.        , 0.        ],\n",
              "       [0.473     , 0.333     , 0.265     , 0.193     , 0.        ],\n",
              "       [0.48799998, 0.393     , 0.244     , 0.132     , 0.073     ],\n",
              "       [0.499     , 0.287     , 0.124     , 0.        , 0.        ],\n",
              "       [0.486     , 0.37100002, 0.109     , 0.        , 0.        ],\n",
              "       [0.497     , 0.343     , 0.188     , 0.        , 0.        ],\n",
              "       [0.48299998, 0.273     , 0.186     , 0.        , 0.        ],\n",
              "       [0.475     , 0.396     , 0.25      , 0.        , 0.        ],\n",
              "       [0.459     , 0.398     , 0.245     , 0.192     , 0.        ],\n",
              "       [0.469     , 0.37899998, 0.25300002, 0.        , 0.        ],\n",
              "       [0.488     , 0.37      , 0.224     , 0.115     , 0.        ],\n",
              "       [0.479     , 0.37600002, 0.254     , 0.112     , 0.        ],\n",
              "       [0.44699997, 0.37299997, 0.169     , 0.        , 0.        ],\n",
              "       [0.624     , 0.32099998, 0.29      , 0.108     , 0.        ],\n",
              "       [0.58      , 0.343     , 0.247     , 0.151     , 0.        ],\n",
              "       [0.48299998, 0.369     , 0.283     , 0.        , 0.        ],\n",
              "       [0.434     , 0.34500003, 0.16999999, 0.145     , 0.        ],\n",
              "       [0.499     , 0.382     , 0.178     , 0.165     , 0.        ],\n",
              "       [0.46999997, 0.25300002, 0.169     , 0.        , 0.        ],\n",
              "       [0.65999997, 0.385     , 0.127     , 0.189     , 0.        ],\n",
              "       [0.49600002, 0.363     , 0.18      , 0.        , 0.        ],\n",
              "       [0.48900002, 0.253     , 0.        , 0.        , 0.        ],\n",
              "       [0.497     , 0.36800003, 0.045     , 0.        , 0.        ],\n",
              "       [0.497     , 0.373     , 0.173     , 0.        , 0.        ],\n",
              "       [0.49600002, 0.34800002, 0.084     , 0.        , 0.        ],\n",
              "       [0.474     , 0.398     , 0.174     , 0.        , 0.        ],\n",
              "       [0.477     , 0.373     , 0.29000002, 0.141     , 0.        ],\n",
              "       [0.499     , 0.319     , 0.176     , 0.        , 0.        ],\n",
              "       [0.49600002, 0.329     , 0.295     , 0.        , 0.        ],\n",
              "       [0.499     , 0.303     , 0.197     , 0.        , 0.        ],\n",
              "       [0.483     , 0.39299998, 0.238     , 0.158     , 0.        ],\n",
              "       [0.48299998, 0.35300002, 0.        , 0.        , 0.        ],\n",
              "       [0.492     , 0.375     , 0.103     , 0.        , 0.        ],\n",
              "       [0.499     , 0.379     , 0.176     , 0.        , 0.        ],\n",
              "       [0.47800002, 0.36      , 0.259     , 0.        , 0.        ],\n",
              "       [0.49199998, 0.315     , 0.109     , 0.        , 0.        ],\n",
              "       [0.47400004, 0.36699998, 0.178     , 0.153     , 0.        ],\n",
              "       [0.477     , 0.389     , 0.19600001, 0.        , 0.        ],\n",
              "       [0.487     , 0.355     , 0.098     , 0.        , 0.        ],\n",
              "       [0.459     , 0.319     , 0.177     , 0.127     , 0.        ],\n",
              "       [0.48800004, 0.317     , 0.151     , 0.        , 0.        ],\n",
              "       [0.48799998, 0.343     , 0.16      , 0.        , 0.        ],\n",
              "       [0.497     , 0.37199998, 0.084     , 0.        , 0.        ],\n",
              "       [0.48799998, 0.27899998, 0.162     , 0.155     , 0.        ],\n",
              "       [0.49899995, 0.314     , 0.232     , 0.136     , 0.        ],\n",
              "       [0.48799998, 0.285     , 0.        , 0.        , 0.        ],\n",
              "       [0.453     , 0.397     , 0.064     , 0.        , 0.        ],\n",
              "       [0.49800003, 0.381     , 0.223     , 0.        , 0.        ],\n",
              "       [0.602     , 0.297     , 0.191     , 0.173     , 0.        ],\n",
              "       [0.48599997, 0.215     , 0.        , 0.        , 0.        ],\n",
              "       [0.49      , 0.387     , 0.243     , 0.        , 0.        ],\n",
              "       [0.533     , 0.35400003, 0.288     , 0.107     , 0.        ],\n",
              "       [0.491     , 0.36399996, 0.197     , 0.18      , 0.        ],\n",
              "       [0.446     , 0.36699998, 0.282     , 0.162     , 0.        ],\n",
              "       [0.47900003, 0.394     , 0.219     , 0.        , 0.        ],\n",
              "       [0.43999997, 0.31      , 0.135     , 0.188     , 0.        ],\n",
              "       [0.471     , 0.338     , 0.255     , 0.        , 0.        ],\n",
              "       [0.49300003, 0.32900003, 0.111     , 0.        , 0.        ],\n",
              "       [0.497     , 0.206     , 0.        , 0.        , 0.        ],\n",
              "       [0.491     , 0.33999997, 0.198     , 0.166     , 0.        ],\n",
              "       [0.498     , 0.39000002, 0.138     , 0.19      , 0.        ],\n",
              "       [0.48600003, 0.365     , 0.235     , 0.        , 0.        ],\n",
              "       [0.483     , 0.255     , 0.15      , 0.        , 0.        ],\n",
              "       [0.493     , 0.378     , 0.24      , 0.152     , 0.        ],\n",
              "       [0.48700002, 0.384     , 0.197     , 0.106     , 0.        ],\n",
              "       [0.40699998, 0.297     , 0.157     , 0.        , 0.        ],\n",
              "       [0.495     , 0.384     , 0.12      , 0.        , 0.        ],\n",
              "       [0.459     , 0.37      , 0.242     , 0.156     , 0.        ],\n",
              "       [0.45899996, 0.335     , 0.152     , 0.166     , 0.        ],\n",
              "       [0.492     , 0.368     , 0.059     , 0.        , 0.        ],\n",
              "       [0.49699998, 0.38600004, 0.123     , 0.        , 0.        ],\n",
              "       [0.47800002, 0.337     , 0.22      , 0.        , 0.        ],\n",
              "       [0.47100002, 0.389     , 0.175     , 0.        , 0.        ],\n",
              "       [0.468     , 0.368     , 0.22799999, 0.182     , 0.        ],\n",
              "       [0.458     , 0.338     , 0.21900001, 0.188     , 0.        ],\n",
              "       [0.485     , 0.331     , 0.291     , 0.        , 0.        ],\n",
              "       [0.669     , 0.328     , 0.185     , 0.149     , 0.        ],\n",
              "       [0.48299998, 0.292     , 0.143     , 0.        , 0.        ],\n",
              "       [0.498     , 0.373     , 0.        , 0.        , 0.        ],\n",
              "       [0.67700005, 0.294     , 0.178     , 0.193     , 0.        ],\n",
              "       [0.482     , 0.37199998, 0.082     , 0.        , 0.        ],\n",
              "       [0.69000006, 0.32999998, 0.145     , 0.161     , 0.        ],\n",
              "       [0.464     , 0.374     , 0.039     , 0.        , 0.        ],\n",
              "       [0.96599996, 0.31      , 0.155     , 0.17      , 0.        ],\n",
              "       [0.486     , 0.39999998, 0.284     , 0.        , 0.        ],\n",
              "       [0.49399996, 0.391     , 0.242     , 0.19      , 0.        ],\n",
              "       [0.489     , 0.399     , 0.218     , 0.        , 0.        ],\n",
              "       [0.49      , 0.187     , 0.        , 0.        , 0.        ],\n",
              "       [0.49      , 0.36499998, 0.111     , 0.19      , 0.        ],\n",
              "       [0.44200003, 0.38200003, 0.21900001, 0.119     , 0.        ],\n",
              "       [0.424     , 0.38699996, 0.289     , 0.156     , 0.        ],\n",
              "       [0.44799998, 0.32700002, 0.122     , 0.        , 0.        ],\n",
              "       [0.42      , 0.348     , 0.191     , 0.16      , 0.        ],\n",
              "       [0.49400002, 0.36699998, 0.192     , 0.        , 0.        ],\n",
              "       [0.487     , 0.36      , 0.144     , 0.        , 0.        ],\n",
              "       [0.459     , 0.37100002, 0.259     , 0.        , 0.        ],\n",
              "       [0.499     , 0.39600003, 0.127     , 0.        , 0.        ],\n",
              "       [0.48999998, 0.26      , 0.159     , 0.147     , 0.        ],\n",
              "       [0.439     , 0.332     , 0.179     , 0.192     , 0.        ],\n",
              "       [0.465     , 0.334     , 0.187     , 0.189     , 0.        ],\n",
              "       [0.615     , 0.356     , 0.251     , 0.177     , 0.        ],\n",
              "       [0.48400003, 0.379     , 0.269     , 0.133     , 0.        ],\n",
              "       [0.49      , 0.37      , 0.25100002, 0.        , 0.        ],\n",
              "       [0.479     , 0.36400002, 0.25      , 0.142     , 0.        ],\n",
              "       [0.49399996, 0.39699998, 0.141     , 0.        , 0.        ],\n",
              "       [0.46100003, 0.265     , 0.186     , 0.199     , 0.        ],\n",
              "       [0.49400005, 0.265     , 0.        , 0.        , 0.        ],\n",
              "       [0.494     , 0.391     , 0.177     , 0.153     , 0.        ],\n",
              "       [0.499     , 0.313     , 0.        , 0.        , 0.        ],\n",
              "       [0.48800004, 0.39400002, 0.199     , 0.        , 0.        ],\n",
              "       [0.488     , 0.374     , 0.        , 0.        , 0.        ],\n",
              "       [0.45099998, 0.339     , 0.        , 0.        , 0.        ],\n",
              "       [0.654     , 0.374     , 0.291     , 0.068     , 0.        ],\n",
              "       [0.48099998, 0.329     , 0.196     , 0.125     , 0.        ],\n",
              "       [0.862     , 0.335     , 0.265     , 0.143     , 0.        ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3P6cSfeOevd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  action = agent1.predict({'input':data[:,i:],'space':dynamic_state,'init':cell})\n",
        "  action_probs = tf.math.divide_no_nan(1.0,action)\n",
        "  action_probs = tf.where(cond, inf, action_probs)\n",
        "  action_probs = tf.nn.softmax(action_probs)\n",
        "  action = tf.math.argmax(action_probs,axis = 1)\n",
        "  action = tf.cast(tf.expand_dims(action, axis = -1), dtype = tf.int64)\n",
        "  action = tf.one_hot(tf.squeeze(action, axis = -1),5,dtype = tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0jY84taaAZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b053d10-4986-4b3e-c778-f2d0b03e491a"
      },
      "source": [
        "agent1.predict({'input':data[:,i:],'space':dynamic_state,'init':cell})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04067285, 0.12970401, 0.1252716 , 0.06536461, 0.        ],\n",
              "       [0.04085384, 0.12970202, 0.12526758, 0.06528489, 0.        ],\n",
              "       [0.04115961, 0.12967679, 0.12531948, 0.06512823, 0.        ],\n",
              "       [0.04164393, 0.1295908 , 0.12551595, 0.06483687, 0.        ],\n",
              "       [0.04142017, 0.12963139, 0.12542559, 0.06497148, 0.        ],\n",
              "       [0.04089319, 0.12970152, 0.12526672, 0.06526756, 0.        ],\n",
              "       [0.04075944, 0.12970309, 0.12526976, 0.06532648, 0.        ],\n",
              "       [0.04128085, 0.12965588, 0.12536904, 0.0650553 , 0.        ],\n",
              "       [0.04068073, 0.1297039 , 0.12527142, 0.06536117, 0.        ],\n",
              "       [0.04129905, 0.12965271, 0.12537639, 0.06504438, 0.        ],\n",
              "       [0.04121417, 0.12966742, 0.12534179, 0.06509544, 0.        ],\n",
              "       [0.04151701, 0.12961401, 0.12546481, 0.06491321, 0.        ],\n",
              "       [0.04155933, 0.12960628, 0.12548189, 0.06488775, 0.        ],\n",
              "       [0.04165602, 0.12958859, 0.12552075, 0.0648296 , 0.        ],\n",
              "       [0.04118386, 0.12967262, 0.1253294 , 0.06511366, 0.        ],\n",
              "       [0.04180694, 0.12956037, 0.12558119, 0.06473882, 0.        ],\n",
              "       [0.04089319, 0.12970152, 0.12526672, 0.06526756, 0.        ],\n",
              "       [0.0419275 , 0.12953731, 0.12562922, 0.0646663 , 0.        ],\n",
              "       [0.04180694, 0.12956037, 0.12558119, 0.06473882, 0.        ],\n",
              "       [0.04187328, 0.12954772, 0.12560765, 0.06469895, 0.        ],\n",
              "       [0.04090891, 0.12970136, 0.12526633, 0.06526063, 0.        ],\n",
              "       [0.0418793 , 0.12954654, 0.12561005, 0.06469529, 0.        ],\n",
              "       [0.04134751, 0.1296442 , 0.12539613, 0.06501517, 0.        ],\n",
              "       [0.04111711, 0.12968402, 0.1253021 , 0.06515381, 0.        ],\n",
              "       [0.04140202, 0.12963457, 0.12541829, 0.06498238, 0.        ],\n",
              "       [0.04149883, 0.1296173 , 0.1254575 , 0.06492414, 0.        ],\n",
              "       [0.04134751, 0.1296442 , 0.12539613, 0.06501517, 0.        ],\n",
              "       [0.04157141, 0.12960409, 0.12548679, 0.06488051, 0.        ],\n",
              "       [0.04186725, 0.12954886, 0.12560524, 0.06470259, 0.        ],\n",
              "       [0.0416077 , 0.12959747, 0.12550133, 0.06485868, 0.        ],\n",
              "       [0.04153515, 0.12961069, 0.12547213, 0.06490231, 0.        ],\n",
              "       [0.04151093, 0.12961508, 0.12546232, 0.06491686, 0.        ],\n",
              "       [0.04180694, 0.12956037, 0.12558119, 0.06473882, 0.        ],\n",
              "       [0.04184915, 0.12955233, 0.12559806, 0.06471344, 0.        ],\n",
              "       [0.04098753, 0.12970026, 0.1252644 , 0.06522603, 0.        ],\n",
              "       [0.04154119, 0.1296096 , 0.12547456, 0.06489867, 0.        ],\n",
              "       [0.04083024, 0.12970231, 0.12526818, 0.06529526, 0.        ],\n",
              "       [0.04184915, 0.12955233, 0.12559806, 0.06471344, 0.        ],\n",
              "       [0.04101899, 0.1296998 , 0.12526368, 0.06521216, 0.        ],\n",
              "       [0.04111711, 0.12968402, 0.1253021 , 0.06515381, 0.        ],\n",
              "       [0.04128085, 0.12965588, 0.12536904, 0.0650553 , 0.        ],\n",
              "       [0.04152909, 0.1296118 , 0.12546968, 0.06490593, 0.        ],\n",
              "       [0.04183107, 0.12955578, 0.12559082, 0.06472433, 0.        ],\n",
              "       [0.04180694, 0.12956037, 0.12558119, 0.06473882, 0.        ],\n",
              "       [0.04182504, 0.12955688, 0.12558842, 0.06472795, 0.        ],\n",
              "       [0.04076732, 0.129703  , 0.12526955, 0.065323  , 0.        ],\n",
              "       [0.04131116, 0.1296506 , 0.12538135, 0.06503704, 0.        ],\n",
              "       [0.04119599, 0.12967055, 0.12533435, 0.0651064 , 0.        ],\n",
              "       [0.04155933, 0.12960628, 0.12548189, 0.06488775, 0.        ],\n",
              "       [0.04121417, 0.12966742, 0.12534179, 0.06509544, 0.        ],\n",
              "       [0.04183107, 0.12955578, 0.12559082, 0.06472433, 0.        ],\n",
              "       [0.04129905, 0.12965271, 0.12537639, 0.06504438, 0.        ],\n",
              "       [0.0418612 , 0.12955005, 0.12560284, 0.06470618, 0.        ],\n",
              "       [0.04151093, 0.12961508, 0.12546232, 0.06491686, 0.        ],\n",
              "       [0.04107465, 0.12969114, 0.12528463, 0.06517938, 0.        ],\n",
              "       [0.0417647 , 0.12956831, 0.12556437, 0.06476422, 0.        ],\n",
              "       [0.04097968, 0.12970038, 0.1252646 , 0.06522946, 0.        ],\n",
              "       [0.04177678, 0.12956601, 0.12556916, 0.06475699, 0.        ],\n",
              "       [0.04075944, 0.12970309, 0.12526976, 0.06532648, 0.        ],\n",
              "       [0.04120205, 0.12966952, 0.12533681, 0.06510272, 0.        ],\n",
              "       [0.04073583, 0.12970334, 0.12527025, 0.06533685, 0.        ],\n",
              "       [0.0412263 , 0.12966534, 0.12534675, 0.06508812, 0.        ],\n",
              "       [0.04169227, 0.12958184, 0.12553534, 0.06480782, 0.        ],\n",
              "       [0.04153515, 0.12961069, 0.12547213, 0.06490231, 0.        ],\n",
              "       [0.04143835, 0.12962812, 0.12543297, 0.06496052, 0.        ],\n",
              "       [0.04123843, 0.12966321, 0.12535167, 0.06508081, 0.        ],\n",
              "       [0.04134146, 0.12964529, 0.12539369, 0.06501885, 0.        ],\n",
              "       [0.04105037, 0.12969522, 0.12527464, 0.06519398, 0.        ],\n",
              "       [0.04103822, 0.12969728, 0.12526964, 0.06520133, 0.        ],\n",
              "       [0.0417828 , 0.1295649 , 0.12557155, 0.06475335, 0.        ],\n",
              "       [0.04085384, 0.12970202, 0.12526758, 0.06528489, 0.        ],\n",
              "       [0.04145044, 0.12962596, 0.1254379 , 0.06495329, 0.        ],\n",
              "       [0.04161373, 0.12959637, 0.12550378, 0.06485506, 0.        ],\n",
              "       [0.04135963, 0.1296421 , 0.12540105, 0.0650079 , 0.        ],\n",
              "       [0.04079879, 0.12970267, 0.12526889, 0.06530914, 0.        ],\n",
              "       [0.04151701, 0.12961401, 0.12546481, 0.06491321, 0.        ],\n",
              "       [0.04123239, 0.1296643 , 0.12534922, 0.06508442, 0.        ],\n",
              "       [0.04143835, 0.12962812, 0.12543297, 0.06496052, 0.        ],\n",
              "       [0.04146255, 0.12962382, 0.12544279, 0.06494598, 0.        ],\n",
              "       [0.04133539, 0.12964633, 0.12539123, 0.06502249, 0.        ],\n",
              "       [0.0413778 , 0.1296389 , 0.12540843, 0.06499697, 0.        ],\n",
              "       [0.04177072, 0.12956713, 0.12556674, 0.06476063, 0.        ],\n",
              "       [0.04167414, 0.12958524, 0.12552807, 0.06481873, 0.        ],\n",
              "       [0.04151093, 0.12961508, 0.12546232, 0.06491686, 0.        ],\n",
              "       [0.04190943, 0.1295408 , 0.12562202, 0.06467717, 0.        ],\n",
              "       [0.04133539, 0.12964633, 0.12539123, 0.06502249, 0.        ],\n",
              "       [0.04142622, 0.1296303 , 0.12542807, 0.06496786, 0.        ],\n",
              "       [0.04131116, 0.1296506 , 0.12538135, 0.06503704, 0.        ],\n",
              "       [0.04071221, 0.12970358, 0.12527078, 0.06534725, 0.        ],\n",
              "       [0.04165602, 0.12958859, 0.12552075, 0.0648296 , 0.        ],\n",
              "       [0.04111108, 0.12968506, 0.12529956, 0.06515747, 0.        ],\n",
              "       [0.04112928, 0.12968196, 0.12530704, 0.06514653, 0.        ],\n",
              "       [0.04153515, 0.12961069, 0.12547213, 0.06490231, 0.        ],\n",
              "       [0.0418612 , 0.12955005, 0.12560284, 0.06470618, 0.        ],\n",
              "       [0.04099539, 0.12970012, 0.12526424, 0.06522255, 0.        ],\n",
              "       [0.04128085, 0.12965588, 0.12536904, 0.0650553 , 0.        ],\n",
              "       [0.04135963, 0.1296421 , 0.12540105, 0.0650079 , 0.        ],\n",
              "       [0.04079879, 0.12970267, 0.12526889, 0.06530914, 0.        ],\n",
              "       [0.04140807, 0.12963349, 0.12542075, 0.06497876, 0.        ],\n",
              "       [0.04126269, 0.12965906, 0.1253616 , 0.06506624, 0.        ],\n",
              "       [0.04161373, 0.12959637, 0.12550378, 0.06485506, 0.        ],\n",
              "       [0.04148072, 0.1296205 , 0.12545015, 0.06493507, 0.        ],\n",
              "       [0.04157141, 0.12960409, 0.12548679, 0.06488051, 0.        ],\n",
              "       [0.04068073, 0.1297039 , 0.12527142, 0.06536117, 0.        ],\n",
              "       [0.04093251, 0.12970102, 0.12526576, 0.06525023, 0.        ],\n",
              "       [0.0412263 , 0.12966534, 0.12534675, 0.06508812, 0.        ],\n",
              "       [0.04140807, 0.12963349, 0.12542075, 0.06497876, 0.        ],\n",
              "       [0.04183709, 0.12955461, 0.12559325, 0.0647207 , 0.        ],\n",
              "       [0.04089319, 0.12970152, 0.12526672, 0.06526756, 0.        ],\n",
              "       [0.04117779, 0.12967364, 0.12532689, 0.06511731, 0.        ],\n",
              "       [0.04096395, 0.1297006 , 0.12526503, 0.0652364 , 0.        ],\n",
              "       [0.04178883, 0.12956376, 0.12557401, 0.06474974, 0.        ],\n",
              "       [0.04071221, 0.12970358, 0.12527078, 0.06534725, 0.        ],\n",
              "       [0.04082239, 0.12970243, 0.12526833, 0.06529873, 0.        ],\n",
              "       [0.04169227, 0.12958184, 0.12553534, 0.06480782, 0.        ],\n",
              "       [0.04188532, 0.12954542, 0.12561244, 0.06469168, 0.        ],\n",
              "       [0.04165602, 0.12958859, 0.12552075, 0.0648296 , 0.        ],\n",
              "       [0.0416983 , 0.12958075, 0.12553778, 0.06480418, 0.        ],\n",
              "       [0.04155329, 0.1296074 , 0.12547949, 0.06489141, 0.        ],\n",
              "       [0.04117173, 0.1296747 , 0.12532441, 0.06512097, 0.        ],\n",
              "       [0.04132329, 0.12964846, 0.12538627, 0.06502977, 0.        ],\n",
              "       [0.04146255, 0.12962382, 0.12544279, 0.06494598, 0.        ],\n",
              "       [0.04082239, 0.12970243, 0.12526833, 0.06529873, 0.        ],\n",
              "       [0.04190943, 0.1295408 , 0.12562202, 0.06467717, 0.        ],\n",
              "       [0.04156537, 0.12960519, 0.12548432, 0.06488414, 0.        ],\n",
              "       [0.04078305, 0.12970284, 0.12526922, 0.06531609, 0.        ],\n",
              "       [0.04114748, 0.12967885, 0.12531449, 0.06513554, 0.        ],\n",
              "       [0.04084598, 0.12970214, 0.12526779, 0.06528833, 0.        ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fhXO29NZb2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed9c69c7-b74e-45f2-e5e3-d9ac502c07d3"
      },
      "source": [
        "compute_all_Q(dynamic_state, data[:,i:],1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 5), dtype=float32, numpy=\n",
              "array([[0.04220916, 0.04204288, 0.04222726, 0.04206713, 0.04210026],\n",
              "       [0.0429012 , 0.04106094, 0.01315821, 0.04121596, 0.01372691],\n",
              "       [0.04311195, 0.0410597 , 0.01301243, 0.0412158 , 0.01336014],\n",
              "       [0.0433759 , 0.04133027, 0.01284268, 0.04140888, 0.01279383],\n",
              "       [0.04268888, 0.04252356, 0.04270095, 0.04255452, 0.04257765],\n",
              "       [0.0423428 , 0.04215699, 0.04234669, 0.04219003, 0.04222551],\n",
              "       [0.04238224, 0.0418747 , 0.04242775, 0.04194995, 0.04205385],\n",
              "       [0.04311497, 0.04129664, 0.01326962, 0.04146313, 0.01340708],\n",
              "       [0.04222872, 0.04202442, 0.0422514 , 0.04205592, 0.04209507],\n",
              "       [0.04259233, 0.04246835, 0.04259499, 0.04249045, 0.04251452],\n",
              "       [0.04297926, 0.04147601, 0.01355483, 0.04163977, 0.01370644],\n",
              "       [0.0433041 , 0.04126664, 0.01294624, 0.04136952, 0.01294685],\n",
              "       [0.04280445, 0.04255654, 0.0428265 , 0.04260618, 0.04262991],\n",
              "       [0.0433041 , 0.04154865, 0.01313521, 0.04166286, 0.01302696],\n",
              "       [0.04255734, 0.04229711, 0.04256294, 0.04234347, 0.04239363],\n",
              "       [0.04345464, 0.04144308, 0.01274418, 0.04149259, 0.01263349],\n",
              "       [0.04277091, 0.04133787, 0.01357675, 0.04147085, 0.0140092 ],\n",
              "       [0.04319613, 0.04238403, 0.04326412, 0.04252451, 0.04263476],\n",
              "       [0.04325915, 0.04197713, 0.01340214, 0.04212195, 0.04236471],\n",
              "       [0.04309088, 0.0425533 , 0.04313359, 0.0426619 , 0.04271454],\n",
              "       [0.0427821 , 0.04133828, 0.01356873, 0.04147303, 0.01399461],\n",
              "       [0.04345464, 0.04159024, 0.01283665, 0.04164731, 0.01267525],\n",
              "       [0.04299039, 0.04172201, 0.01370876, 0.04188314, 0.04211317],\n",
              "       [0.04306094, 0.0411027 , 0.01312498, 0.04126704, 0.01348434],\n",
              "       [0.04326215, 0.04114683, 0.01288247, 0.04125939, 0.01301956],\n",
              "       [0.04300155, 0.0420078 , 0.01380964, 0.042158  , 0.04231207],\n",
              "       [0.04297554, 0.0417543 , 0.01374037, 0.04191247, 0.04213193],\n",
              "       [0.04334298, 0.04127203, 0.01287319, 0.04136163, 0.0128557 ],\n",
              "       [0.04338187, 0.04176803, 0.01309569, 0.04186372, 0.0422484 ],\n",
              "       [0.04327414, 0.04153127, 0.01318863, 0.04165523, 0.01309336],\n",
              "       [0.04331008, 0.04128726, 0.01294913, 0.0413889 , 0.01293843],\n",
              "       [0.04295325, 0.04213936, 0.04298253, 0.04227092, 0.0423896 ],\n",
              "       [0.04348803, 0.04134609, 0.01260917, 0.04137506, 0.01252056],\n",
              "       [0.04325614, 0.04207136, 0.01341226, 0.04221607, 0.04242893],\n",
              "       [0.04240414, 0.04219354, 0.04240858, 0.04223103, 0.04227135],\n",
              "       [0.04336693, 0.04114626, 0.01271824, 0.04121976, 0.01276787],\n",
              "       [0.04249173, 0.04178625, 0.01424208, 0.04187917, 0.04203553],\n",
              "       [0.04349448, 0.04140761, 0.01262937, 0.04143595, 0.01251664],\n",
              "       [0.0429198 , 0.04121235, 0.01335278, 0.04137125, 0.01376218],\n",
              "       [0.04270009, 0.04188077, 0.01415051, 0.0419948 , 0.04215423],\n",
              "       [0.04305721, 0.04144171, 0.01347096, 0.04161864, 0.01357517],\n",
              "       [0.04283051, 0.04244139, 0.04286134, 0.04251658, 0.04256054],\n",
              "       [0.04305719, 0.04255005, 0.0430951 , 0.04265182, 0.04270104],\n",
              "       [0.04323817, 0.04203385, 0.01344171, 0.04218512, 0.04239899],\n",
              "       [0.04302752, 0.04259919, 0.04306325, 0.04268513, 0.04272681],\n",
              "       [0.04260542, 0.04149908, 0.01385882, 0.04159233, 0.01426784],\n",
              "       [0.04278212, 0.04210014, 0.04279127, 0.04221022, 0.04232369],\n",
              "       [0.04258796, 0.04226577, 0.04259322, 0.04232316, 0.04238524],\n",
              "       [0.04293837, 0.04227037, 0.0429753 , 0.04239051, 0.04247596],\n",
              "       [0.0426553 , 0.0421747 , 0.04265753, 0.04226078, 0.04234442],\n",
              "       [0.04307885, 0.04250472, 0.04311911, 0.04262009, 0.04267572],\n",
              "       [0.04257919, 0.04249243, 0.04258108, 0.04250789, 0.04252473],\n",
              "       [0.0435009 , 0.04140787, 0.01261104, 0.04143233, 0.01249535],\n",
              "       [0.04316609, 0.04162569, 0.01344718, 0.04179099, 0.01337721],\n",
              "       [0.04256172, 0.0420663 , 0.04255703, 0.04214941, 0.04224887],\n",
              "       [0.04340249, 0.04150275, 0.01289389, 0.04157867, 0.01277865],\n",
              "       [0.04236469, 0.0422532 , 0.04236704, 0.04227303, 0.04229441],\n",
              "       [0.04344016, 0.0414222 , 0.01276189, 0.0414771 , 0.01266317],\n",
              "       [0.04294953, 0.04089932, 0.01282523, 0.01705929, 0.01355366],\n",
              "       [0.04279328, 0.04185365, 0.01401367, 0.04198194, 0.04215665],\n",
              "       [0.04268142, 0.04133438, 0.01361315, 0.04142978, 0.01409192],\n",
              "       [0.04276719, 0.04195913, 0.04277473, 0.04207709, 0.04222338],\n",
              "       [0.04304608, 0.04230925, 0.04308545, 0.04244235, 0.04252759],\n",
              "       [0.04303125, 0.04201672, 0.0137706 , 0.0421715 , 0.04232576],\n",
              "       [0.0429012 , 0.04210326, 0.04292303, 0.04223001, 0.04235296],\n",
              "       [0.04267769, 0.0421761 , 0.04268314, 0.04226608, 0.04235094],\n",
              "       [0.04265157, 0.04244276, 0.04265807, 0.0424803 , 0.04251636],\n",
              "       [0.04294211, 0.04122537, 0.0133462 , 0.0413876 , 0.01372791],\n",
              "       [0.04252237, 0.0420641 , 0.04252264, 0.04214264, 0.04223328],\n",
              "       [0.04344594, 0.04141829, 0.0127471 , 0.04147038, 0.01264781],\n",
              "       [0.04238225, 0.04202312, 0.0424049 , 0.04208699, 0.04215533],\n",
              "       [0.04284541, 0.04224833, 0.04287778, 0.04235683, 0.04243962],\n",
              "       [0.04338186, 0.04125287, 0.01278082, 0.04132482, 0.01275763],\n",
              "       [0.04322316, 0.04116586, 0.01296086, 0.04129267, 0.01311749],\n",
              "       [0.04296441, 0.04090709, 0.01284529, 0.01701637, 0.01354192],\n",
              "       [0.04322917, 0.04146839, 0.01323826, 0.04160549, 0.0131825 ],\n",
              "       [0.04295325, 0.04156926, 0.01365973, 0.04172723, 0.01376552],\n",
              "       [0.04322015, 0.04133319, 0.01315955, 0.04146797, 0.01316546],\n",
              "       [0.04295325, 0.04204021, 0.04297161, 0.04217907, 0.04232169],\n",
              "       [0.0430498 , 0.04156831, 0.01357083, 0.04174177, 0.01361071],\n",
              "       [0.04324417, 0.0411462 , 0.01290748, 0.04126491, 0.01306256],\n",
              "       [0.04303496, 0.0424828 , 0.04307324, 0.04259355, 0.0426468 ],\n",
              "       [0.04285657, 0.04266493, 0.04287364, 0.04270334, 0.04272189],\n",
              "       [0.04323217, 0.04144805, 0.01321784, 0.04158328, 0.01316958],\n",
              "       [0.04344885, 0.0416678 , 0.01289769, 0.0417314 , 0.0421936 ],\n",
              "       [0.0428119 , 0.04208549, 0.04282239, 0.04220083, 0.04232039],\n",
              "       [0.04319913, 0.04136513, 0.01322384, 0.04150851, 0.01322449],\n",
              "       [0.04310293, 0.04139019, 0.0133829 , 0.04156249, 0.01346012],\n",
              "       [0.04239101, 0.04179624, 0.0143174 , 0.0418663 , 0.04200757],\n",
              "       [0.04339668, 0.04129823, 0.01277743, 0.04136611, 0.01273487],\n",
              "       [0.04245672, 0.04233277, 0.04245935, 0.04235483, 0.04237871],\n",
              "       [0.04280816, 0.0416741 , 0.01386647, 0.04180776, 0.01401736],\n",
              "       [0.04317812, 0.04164252, 0.01343883, 0.04180427, 0.01335343],\n",
              "       [0.04325614, 0.04209626, 0.01341255, 0.04224037, 0.04244588],\n",
              "       [0.04266649, 0.04171807, 0.01403727, 0.04183254, 0.04203435],\n",
              "       [0.04269262, 0.04223067, 0.04270251, 0.04231459, 0.04238996],\n",
              "       [0.04316008, 0.04133509, 0.01325138, 0.04149087, 0.01330876],\n",
              "       [0.04225944, 0.04216036, 0.04225775, 0.04217796, 0.04219684],\n",
              "       [0.04309694, 0.04160266, 0.01353001, 0.04178392, 0.01353392],\n",
              "       [0.04321714, 0.04098612, 0.0127445 , 0.04111237, 0.01309262],\n",
              "       [0.043346  , 0.04134971, 0.01291929, 0.04144146, 0.01287063],\n",
              "       [0.04309694, 0.04175009, 0.01359962, 0.04192865, 0.04216032],\n",
              "       [0.04280072, 0.0425866 , 0.04281977, 0.04262949, 0.04264999],\n",
              "       [0.04236032, 0.04180824, 0.01434728, 0.04186705, 0.042004  ],\n",
              "       [0.04239978, 0.04211488, 0.04240321, 0.04216558, 0.04221994],\n",
              "       [0.04288261, 0.04171022, 0.01382168, 0.04185432, 0.04207821],\n",
              "       [0.04271125, 0.04245061, 0.0427293 , 0.04249924, 0.0425364 ],\n",
              "       [0.04317209, 0.04227543, 0.04322712, 0.04242643, 0.04254502],\n",
              "       [0.04235156, 0.04214098, 0.04235597, 0.04217844, 0.04221863],\n",
              "       [0.04284541, 0.04169255, 0.01385199, 0.04183103, 0.04205601],\n",
              "       [0.04257919, 0.04183648, 0.0142253 , 0.04193791, 0.04209853],\n",
              "       [0.04327716, 0.04189166, 0.01335458, 0.04202844, 0.04230982],\n",
              "       [0.0423428 , 0.04187845, 0.04239204, 0.04194292, 0.04204293],\n",
              "       [0.04261855, 0.04154322, 0.01390278, 0.04165482, 0.01428139],\n",
              "       [0.04336993, 0.04144448, 0.0129278 , 0.04153167, 0.01284049],\n",
              "       [0.04324115, 0.04218723, 0.04330318, 0.0423341 , 0.04250426],\n",
              "       [0.04334898, 0.04142746, 0.01296205, 0.04152127, 0.01288556],\n",
              "       [0.0431691 , 0.04199865, 0.01355592, 0.04217179, 0.04235465],\n",
              "       [0.04319013, 0.04164703, 0.01342213, 0.04180476, 0.01332616],\n",
              "       [0.04309391, 0.04113246, 0.0131176 , 0.04129423, 0.01341925],\n",
              "       [0.04285285, 0.04197264, 0.04285403, 0.04210178, 0.04225214],\n",
              "       [0.04268888, 0.04261002, 0.04269592, 0.04262578, 0.0426333 ],\n",
              "       [0.04248298, 0.04178986, 0.01425239, 0.04188171, 0.04203491],\n",
              "       [0.04309391, 0.04261326, 0.04313629, 0.0427106 , 0.04275802],\n",
              "       [0.04279328, 0.04259042, 0.04281132, 0.04263104, 0.04265049],\n",
              "       [0.04227699, 0.04210358, 0.04227914, 0.04213443, 0.04216673],\n",
              "       [0.04303867, 0.04121222, 0.01325037, 0.04138395, 0.01355592],\n",
              "       [0.04300897, 0.04087089, 0.01276925, 0.0170614 , 0.01345745]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZTzrzAH-3FC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a98a53d-c0ab-48b6-c4f6-a385b0a283df"
      },
      "source": [
        "action"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04067285, 0.12970401, 0.1252716 , 0.06536461, 0.        ],\n",
              "       [0.04085384, 0.12970202, 0.12526758, 0.06528489, 0.        ],\n",
              "       [0.04115961, 0.12967679, 0.12531948, 0.06512823, 0.        ],\n",
              "       [0.04164393, 0.1295908 , 0.12551595, 0.06483687, 0.        ],\n",
              "       [0.04142017, 0.12963139, 0.12542559, 0.06497148, 0.        ],\n",
              "       [0.04089319, 0.12970152, 0.12526672, 0.06526756, 0.        ],\n",
              "       [0.04075944, 0.12970309, 0.12526976, 0.06532648, 0.        ],\n",
              "       [0.04128085, 0.12965588, 0.12536904, 0.0650553 , 0.        ],\n",
              "       [0.04068073, 0.1297039 , 0.12527142, 0.06536117, 0.        ],\n",
              "       [0.04129905, 0.12965271, 0.12537639, 0.06504438, 0.        ],\n",
              "       [0.04121417, 0.12966742, 0.12534179, 0.06509544, 0.        ],\n",
              "       [0.04151701, 0.12961401, 0.12546481, 0.06491321, 0.        ],\n",
              "       [0.04155933, 0.12960628, 0.12548189, 0.06488775, 0.        ],\n",
              "       [0.04165602, 0.12958859, 0.12552075, 0.0648296 , 0.        ],\n",
              "       [0.04118386, 0.12967262, 0.1253294 , 0.06511366, 0.        ],\n",
              "       [0.04180694, 0.12956037, 0.12558119, 0.06473882, 0.        ],\n",
              "       [0.04089319, 0.12970152, 0.12526672, 0.06526756, 0.        ],\n",
              "       [0.0419275 , 0.12953731, 0.12562922, 0.0646663 , 0.        ],\n",
              "       [0.04180694, 0.12956037, 0.12558119, 0.06473882, 0.        ],\n",
              "       [0.04187328, 0.12954772, 0.12560765, 0.06469895, 0.        ],\n",
              "       [0.04090891, 0.12970136, 0.12526633, 0.06526063, 0.        ],\n",
              "       [0.0418793 , 0.12954654, 0.12561005, 0.06469529, 0.        ],\n",
              "       [0.04134751, 0.1296442 , 0.12539613, 0.06501517, 0.        ],\n",
              "       [0.04111711, 0.12968402, 0.1253021 , 0.06515381, 0.        ],\n",
              "       [0.04140202, 0.12963457, 0.12541829, 0.06498238, 0.        ],\n",
              "       [0.04149883, 0.1296173 , 0.1254575 , 0.06492414, 0.        ],\n",
              "       [0.04134751, 0.1296442 , 0.12539613, 0.06501517, 0.        ],\n",
              "       [0.04157141, 0.12960409, 0.12548679, 0.06488051, 0.        ],\n",
              "       [0.04186725, 0.12954886, 0.12560524, 0.06470259, 0.        ],\n",
              "       [0.0416077 , 0.12959747, 0.12550133, 0.06485868, 0.        ],\n",
              "       [0.04153515, 0.12961069, 0.12547213, 0.06490231, 0.        ],\n",
              "       [0.04151093, 0.12961508, 0.12546232, 0.06491686, 0.        ],\n",
              "       [0.04180694, 0.12956037, 0.12558119, 0.06473882, 0.        ],\n",
              "       [0.04184915, 0.12955233, 0.12559806, 0.06471344, 0.        ],\n",
              "       [0.04098753, 0.12970026, 0.1252644 , 0.06522603, 0.        ],\n",
              "       [0.04154119, 0.1296096 , 0.12547456, 0.06489867, 0.        ],\n",
              "       [0.04083024, 0.12970231, 0.12526818, 0.06529526, 0.        ],\n",
              "       [0.04184915, 0.12955233, 0.12559806, 0.06471344, 0.        ],\n",
              "       [0.04101899, 0.1296998 , 0.12526368, 0.06521216, 0.        ],\n",
              "       [0.04111711, 0.12968402, 0.1253021 , 0.06515381, 0.        ],\n",
              "       [0.04128085, 0.12965588, 0.12536904, 0.0650553 , 0.        ],\n",
              "       [0.04152909, 0.1296118 , 0.12546968, 0.06490593, 0.        ],\n",
              "       [0.04183107, 0.12955578, 0.12559082, 0.06472433, 0.        ],\n",
              "       [0.04180694, 0.12956037, 0.12558119, 0.06473882, 0.        ],\n",
              "       [0.04182504, 0.12955688, 0.12558842, 0.06472795, 0.        ],\n",
              "       [0.04076732, 0.129703  , 0.12526955, 0.065323  , 0.        ],\n",
              "       [0.04131116, 0.1296506 , 0.12538135, 0.06503704, 0.        ],\n",
              "       [0.04119599, 0.12967055, 0.12533435, 0.0651064 , 0.        ],\n",
              "       [0.04155933, 0.12960628, 0.12548189, 0.06488775, 0.        ],\n",
              "       [0.04121417, 0.12966742, 0.12534179, 0.06509544, 0.        ],\n",
              "       [0.04183107, 0.12955578, 0.12559082, 0.06472433, 0.        ],\n",
              "       [0.04129905, 0.12965271, 0.12537639, 0.06504438, 0.        ],\n",
              "       [0.0418612 , 0.12955005, 0.12560284, 0.06470618, 0.        ],\n",
              "       [0.04151093, 0.12961508, 0.12546232, 0.06491686, 0.        ],\n",
              "       [0.04107465, 0.12969114, 0.12528463, 0.06517938, 0.        ],\n",
              "       [0.0417647 , 0.12956831, 0.12556437, 0.06476422, 0.        ],\n",
              "       [0.04097968, 0.12970038, 0.1252646 , 0.06522946, 0.        ],\n",
              "       [0.04177678, 0.12956601, 0.12556916, 0.06475699, 0.        ],\n",
              "       [0.04075944, 0.12970309, 0.12526976, 0.06532648, 0.        ],\n",
              "       [0.04120205, 0.12966952, 0.12533681, 0.06510272, 0.        ],\n",
              "       [0.04073583, 0.12970334, 0.12527025, 0.06533685, 0.        ],\n",
              "       [0.0412263 , 0.12966534, 0.12534675, 0.06508812, 0.        ],\n",
              "       [0.04169227, 0.12958184, 0.12553534, 0.06480782, 0.        ],\n",
              "       [0.04153515, 0.12961069, 0.12547213, 0.06490231, 0.        ],\n",
              "       [0.04143835, 0.12962812, 0.12543297, 0.06496052, 0.        ],\n",
              "       [0.04123843, 0.12966321, 0.12535167, 0.06508081, 0.        ],\n",
              "       [0.04134146, 0.12964529, 0.12539369, 0.06501885, 0.        ],\n",
              "       [0.04105037, 0.12969522, 0.12527464, 0.06519398, 0.        ],\n",
              "       [0.04103822, 0.12969728, 0.12526964, 0.06520133, 0.        ],\n",
              "       [0.0417828 , 0.1295649 , 0.12557155, 0.06475335, 0.        ],\n",
              "       [0.04085384, 0.12970202, 0.12526758, 0.06528489, 0.        ],\n",
              "       [0.04145044, 0.12962596, 0.1254379 , 0.06495329, 0.        ],\n",
              "       [0.04161373, 0.12959637, 0.12550378, 0.06485506, 0.        ],\n",
              "       [0.04135963, 0.1296421 , 0.12540105, 0.0650079 , 0.        ],\n",
              "       [0.04079879, 0.12970267, 0.12526889, 0.06530914, 0.        ],\n",
              "       [0.04151701, 0.12961401, 0.12546481, 0.06491321, 0.        ],\n",
              "       [0.04123239, 0.1296643 , 0.12534922, 0.06508442, 0.        ],\n",
              "       [0.04143835, 0.12962812, 0.12543297, 0.06496052, 0.        ],\n",
              "       [0.04146255, 0.12962382, 0.12544279, 0.06494598, 0.        ],\n",
              "       [0.04133539, 0.12964633, 0.12539123, 0.06502249, 0.        ],\n",
              "       [0.0413778 , 0.1296389 , 0.12540843, 0.06499697, 0.        ],\n",
              "       [0.04177072, 0.12956713, 0.12556674, 0.06476063, 0.        ],\n",
              "       [0.04167414, 0.12958524, 0.12552807, 0.06481873, 0.        ],\n",
              "       [0.04151093, 0.12961508, 0.12546232, 0.06491686, 0.        ],\n",
              "       [0.04190943, 0.1295408 , 0.12562202, 0.06467717, 0.        ],\n",
              "       [0.04133539, 0.12964633, 0.12539123, 0.06502249, 0.        ],\n",
              "       [0.04142622, 0.1296303 , 0.12542807, 0.06496786, 0.        ],\n",
              "       [0.04131116, 0.1296506 , 0.12538135, 0.06503704, 0.        ],\n",
              "       [0.04071221, 0.12970358, 0.12527078, 0.06534725, 0.        ],\n",
              "       [0.04165602, 0.12958859, 0.12552075, 0.0648296 , 0.        ],\n",
              "       [0.04111108, 0.12968506, 0.12529956, 0.06515747, 0.        ],\n",
              "       [0.04112928, 0.12968196, 0.12530704, 0.06514653, 0.        ],\n",
              "       [0.04153515, 0.12961069, 0.12547213, 0.06490231, 0.        ],\n",
              "       [0.0418612 , 0.12955005, 0.12560284, 0.06470618, 0.        ],\n",
              "       [0.04099539, 0.12970012, 0.12526424, 0.06522255, 0.        ],\n",
              "       [0.04128085, 0.12965588, 0.12536904, 0.0650553 , 0.        ],\n",
              "       [0.04135963, 0.1296421 , 0.12540105, 0.0650079 , 0.        ],\n",
              "       [0.04079879, 0.12970267, 0.12526889, 0.06530914, 0.        ],\n",
              "       [0.04140807, 0.12963349, 0.12542075, 0.06497876, 0.        ],\n",
              "       [0.04126269, 0.12965906, 0.1253616 , 0.06506624, 0.        ],\n",
              "       [0.04161373, 0.12959637, 0.12550378, 0.06485506, 0.        ],\n",
              "       [0.04148072, 0.1296205 , 0.12545015, 0.06493507, 0.        ],\n",
              "       [0.04157141, 0.12960409, 0.12548679, 0.06488051, 0.        ],\n",
              "       [0.04068073, 0.1297039 , 0.12527142, 0.06536117, 0.        ],\n",
              "       [0.04093251, 0.12970102, 0.12526576, 0.06525023, 0.        ],\n",
              "       [0.0412263 , 0.12966534, 0.12534675, 0.06508812, 0.        ],\n",
              "       [0.04140807, 0.12963349, 0.12542075, 0.06497876, 0.        ],\n",
              "       [0.04183709, 0.12955461, 0.12559325, 0.0647207 , 0.        ],\n",
              "       [0.04089319, 0.12970152, 0.12526672, 0.06526756, 0.        ],\n",
              "       [0.04117779, 0.12967364, 0.12532689, 0.06511731, 0.        ],\n",
              "       [0.04096395, 0.1297006 , 0.12526503, 0.0652364 , 0.        ],\n",
              "       [0.04178883, 0.12956376, 0.12557401, 0.06474974, 0.        ],\n",
              "       [0.04071221, 0.12970358, 0.12527078, 0.06534725, 0.        ],\n",
              "       [0.04082239, 0.12970243, 0.12526833, 0.06529873, 0.        ],\n",
              "       [0.04169227, 0.12958184, 0.12553534, 0.06480782, 0.        ],\n",
              "       [0.04188532, 0.12954542, 0.12561244, 0.06469168, 0.        ],\n",
              "       [0.04165602, 0.12958859, 0.12552075, 0.0648296 , 0.        ],\n",
              "       [0.0416983 , 0.12958075, 0.12553778, 0.06480418, 0.        ],\n",
              "       [0.04155329, 0.1296074 , 0.12547949, 0.06489141, 0.        ],\n",
              "       [0.04117173, 0.1296747 , 0.12532441, 0.06512097, 0.        ],\n",
              "       [0.04132329, 0.12964846, 0.12538627, 0.06502977, 0.        ],\n",
              "       [0.04146255, 0.12962382, 0.12544279, 0.06494598, 0.        ],\n",
              "       [0.04082239, 0.12970243, 0.12526833, 0.06529873, 0.        ],\n",
              "       [0.04190943, 0.1295408 , 0.12562202, 0.06467717, 0.        ],\n",
              "       [0.04156537, 0.12960519, 0.12548432, 0.06488414, 0.        ],\n",
              "       [0.04078305, 0.12970284, 0.12526922, 0.06531609, 0.        ],\n",
              "       [0.04114748, 0.12967885, 0.12531449, 0.06513554, 0.        ],\n",
              "       [0.04084598, 0.12970214, 0.12526779, 0.06528833, 0.        ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syYVsaDTm4VF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "3b7d1201-e700-467c-d2c8-3dae0bc55460"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe9c5367128>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwCKfSHNnNgJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c836c57-3ea5-4e57-e323-d859cb0e411f"
      },
      "source": [
        "compute_all_Q(state,data,choice)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 5), dtype=float32, numpy=\n",
              "array([[1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETWd0A-UZ6Oy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "857b1879-3c35-49d7-8e0b-63a33ab928da"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=int64, numpy=\n",
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T8IFeifaOCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states = tf.math.multiply(action, tf.ones((10,1), dtype = tf.float32)) + state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1BVg2HWat7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reshape(states, [5,10,5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ1QW2Oray1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [random.sample(range(1,50),15) for i in range(10)]\n",
        "data = np.array(data)\n",
        "def normalize(input_data):\n",
        "    return input_data.astype(np.float32)/1000.0\n",
        "data = normalize(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5ck5KKja7V_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0385e8a0-1a00-415b-ff0f-4a4a5abb6306"
      },
      "source": [
        "k = agent2.predict({'input':data,'space':dynamic_state,'init':cell})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 1) for input Tensor(\"input_4:0\", shape=(None, 1), dtype=float32), but it was called on an input with incompatible shape (32, 6).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqNM00a5bN9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "qs = []\n",
        "for i in range(5):\n",
        "  q = agent.predict({'input':data,'space':states[i],'init':cell})\n",
        "  q = tf.math.reduce_max(q, axis = 1)\n",
        "  qs.append(tf.expand_dims(q,axis = -1))\n",
        "qs = tf.concat(qs, axis = -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtpGBiQem_Z8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "18573adb-24c2-44ab-bb6b-e28eba556a4b"
      },
      "source": [
        "data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(11,), dtype=float32, numpy=\n",
              "array([0.03 , 0.179, 0.112, 0.174, 0.18 , 0.148, 0.136, 0.188, 0.108,\n",
              "       0.197, 0.029], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZEWY_nS0YKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = agent2.train_on_batch({'input':data,'space':dynamic_state,'init':cell}, total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg9mfGpynL2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "31b927e2-2576-4b3a-a79e-7cab072b7c68"
      },
      "source": [
        "tf.math.reduce_max(tf.expand_dims(states, axis = -2), axis = 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 10, 1), dtype=float32, numpy=\n",
              "array([[[2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.]],\n",
              "\n",
              "       [[2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.]],\n",
              "\n",
              "       [[2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.]],\n",
              "\n",
              "       [[2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.]],\n",
              "\n",
              "       [[2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.],\n",
              "        [2.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpM1x6cHnndp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ef9a3144-e042-4343-c472-b4e684b36a7c"
      },
      "source": [
        "tf.math.reduce_max(q, axis = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([0.01292582, 0.01292582, 0.01292582, 0.01292582, 0.01292582,\n",
              "       0.01292582, 0.01292582, 0.01292582, 0.01292582, 0.01292582],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TPPbO--n2CI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}